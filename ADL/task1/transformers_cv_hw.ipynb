{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfVh6P2PLAD7"
      },
      "source": [
        "# DS-поток, весна 2025\n",
        "## Задание ADL.1\n",
        "\n",
        "\n",
        "**Правила:**\n",
        "\n",
        "* Дедлайны см. в боте. После дедлайна работы не принимаются кроме случаев наличия уважительной причины.\n",
        "* Прислать нужно **ноутбук в формате `ipynb`**.\n",
        "* Следите за размером файлов. **Бот не может принимать файлы весом более 20 Мб.** Если файл получается больше, заранее разделите его на несколько.\n",
        "* Выполнять задание необходимо полностью самостоятельно. **При обнаружении списывания все участники списывания будут сдавать устный зачет.**\n",
        "* Решения, размещенные на каких-либо интернет-ресурсах, не принимаются. Кроме того, публикация решения в открытом доступе может быть приравнена к предоставлении возможности списать.\n",
        "* Для выполнения задания используйте этот ноутбук в качестве основы, ничего не удаляя из него. Можно добавлять необходимое количество ячеек.\n",
        "* Комментарииь к решению пишите в markdown-ячейках.\n",
        "* Выполнение задания (ход решения, выводы и пр.) должно быть осуществлено на русском языке.\n",
        "* Если код будет не понятен проверяющему, оценка может быть снижена.\n",
        "* Никакой код из данного задания при проверке запускаться не будет. *Если код студента не выполнен, недописан и т.д., то он не оценивается.*\n",
        "* В каждой задаче не забывайте делать **пояснения и выводы**.\n",
        "\n",
        "\n",
        "**Баллы за задание**  \n",
        "Задача 1 &mdash; **90 баллов**  \n",
        "Задача 2 &mdash; **30 баллов**\n",
        "\n",
        "Всего &mdash; **120 баллов**  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vw0FWSG-K2z4"
      },
      "outputs": [],
      "source": [
        "# Bot check\n",
        "\n",
        "# HW_ID: ds_adl1\n",
        "# Бот проверит этот ID и предупредит, если случайно сдать что-то не то.\n",
        "\n",
        "# Status: not final\n",
        "# Перед отправкой в финальном решении удали \"not\" в строчке выше.\n",
        "# Так бот проверит, что ты отправляешь финальную версию, а не промежуточную\n",
        "# Никакие значения в этой ячейке не влияют на факт сдачи работы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IEOS5nmOigG3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "from functools import lru_cache\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6tve1_zO4Cp"
      },
      "source": [
        "## Задача 1 &mdash; обучение моделей на разном объеме данных\n",
        "\n",
        "В этой задаче нужно определить зависимость качества модели от размера обучающих данных и сравнить между собой сверточную и трансформерную модель.\n",
        "\n",
        "В качестве данных будем использовать [датасет](https://www.kaggle.com/datasets/paramaggarwal/fashion-product-images-dataset) с фотографиями одежды и аксессуаров. В качестве лейблов классификации используем поле `subCategory` в `styles`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_P8BQUHlAXxT"
      },
      "source": [
        "### 1. Подготовка данных\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8ML-0LOyrE5"
      },
      "outputs": [],
      "source": [
        "# Если нужно распаковать zip\n",
        "import zipfile\n",
        "zip_file_path = <...>\n",
        "extract_to_directory = '.'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    file_list = zip_ref.namelist()\n",
        "    for file in tqdm(file_list, desc=\"Extracting files\", unit=\"files\"):\n",
        "        zip_ref.extract(file, extract_to_directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOmXDjt92PMC"
      },
      "source": [
        "Для начала определим пути до изображений и таблицы с описанием товаров."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-10T14:04:55.614915Z",
          "iopub.status.busy": "2023-05-10T14:04:55.613498Z",
          "iopub.status.idle": "2023-05-10T14:04:55.620126Z",
          "shell.execute_reply": "2023-05-10T14:04:55.619222Z",
          "shell.execute_reply.started": "2023-05-10T14:04:55.614877Z"
        },
        "id": "14-feCkLAXxU"
      },
      "outputs": [],
      "source": [
        "root = Path('fashion-dataset')\n",
        "images_root = root / 'images'\n",
        "styles_path = root / 'styles.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3KdrgERAXxU"
      },
      "source": [
        "Считаем таблицу с описанием товаров. Заметим, что нас интересует только одна колонка &mdash; `subCategory`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-10T14:04:55.623280Z",
          "iopub.status.busy": "2023-05-10T14:04:55.622857Z",
          "iopub.status.idle": "2023-05-10T14:04:55.755501Z",
          "shell.execute_reply": "2023-05-10T14:04:55.754338Z",
          "shell.execute_reply.started": "2023-05-10T14:04:55.623235Z"
        },
        "id": "6ZeU5-kDiIx2"
      },
      "outputs": [],
      "source": [
        "styles_df = pd.read_csv(styles_path, usecols=['id', 'subCategory'], index_col='id')\n",
        "styles_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHfQdshxAXxV"
      },
      "source": [
        "Заметим, что количество изображений близко, но не точно равно количеству товаров в таблице с описанием."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-10T14:04:55.757361Z",
          "iopub.status.busy": "2023-05-10T14:04:55.756890Z",
          "iopub.status.idle": "2023-05-10T14:04:56.708365Z",
          "shell.execute_reply": "2023-05-10T14:04:56.707308Z",
          "shell.execute_reply.started": "2023-05-10T14:04:55.757323Z"
        },
        "id": "b1hZFB1CAXxW"
      },
      "outputs": [],
      "source": [
        "len(list(images_root.iterdir())), len(styles_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uan4VfaZAXxW"
      },
      "source": [
        "При этом идентификаторы изображений уникальны, а среди идентификаторов в таблице с описанием есть несколько повторений."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2023-05-10T14:04:56.710158Z",
          "iopub.status.busy": "2023-05-10T14:04:56.709831Z",
          "iopub.status.idle": "2023-05-10T14:04:56.834923Z",
          "shell.execute_reply": "2023-05-10T14:04:56.833773Z",
          "shell.execute_reply.started": "2023-05-10T14:04:56.710133Z"
        },
        "id": "TwrAOh_7AXxW"
      },
      "outputs": [],
      "source": [
        "ids1 = [int(path.name.split('.')[0]) for path in images_root.iterdir()]\n",
        "ids2 = styles_df.index.tolist()\n",
        "print(len(set(ids1) & set(ids2)) == len(ids1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD7yGyUtAXxX"
      },
      "source": [
        "Посчитаем количество различных лейблов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-10T14:04:56.836937Z",
          "iopub.status.busy": "2023-05-10T14:04:56.836565Z",
          "iopub.status.idle": "2023-05-10T14:04:56.893371Z",
          "shell.execute_reply": "2023-05-10T14:04:56.892347Z",
          "shell.execute_reply.started": "2023-05-10T14:04:56.836902Z"
        },
        "id": "WV2kKBhaAXxX"
      },
      "outputs": [],
      "source": [
        "labels = styles_df.loc[ids1]['subCategory'].values\n",
        "val, cnt = np.unique(labels, return_counts=True)\n",
        "cnt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41LIF7BhAXxX"
      },
      "source": [
        "Отсечем все классы, которые встречаются слишком редко &mdash; меньше 100 экземпляров. Для них оставим соответствующие идентификаторы. Визуализируем некоторые картинки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-10T14:04:56.904697Z",
          "iopub.status.busy": "2023-05-10T14:04:56.904047Z",
          "iopub.status.idle": "2023-05-10T14:06:40.264827Z",
          "shell.execute_reply": "2023-05-10T14:06:40.263605Z",
          "shell.execute_reply.started": "2023-05-10T14:04:56.904651Z"
        },
        "id": "4-kgCCS2AXxY"
      },
      "outputs": [],
      "source": [
        "labels_unique = val[cnt >= 100]\n",
        "len(labels_unique)\n",
        "\n",
        "fig, axs = plt.subplots(27, 9, figsize=(18, 54))\n",
        "for i, label in enumerate(labels_unique):\n",
        "    ids = styles_df[styles_df['subCategory'] == label].index[:9]\n",
        "    for j, id in enumerate(ids):\n",
        "        image = Image.open(images_root / f'{id}.jpg')\n",
        "        axs[i, j].imshow(image)\n",
        "        axs[i, j].set_title(f\"{label}, {i}\")\n",
        "        axs[i, j].axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pkErEr-AXxY"
      },
      "source": [
        "Можно заметить, что есть классы товаров, которые могут включать в себя другие классы товаров."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-10T14:06:40.270944Z",
          "iopub.status.busy": "2023-05-10T14:06:40.269476Z",
          "iopub.status.idle": "2023-05-10T14:06:40.331948Z",
          "shell.execute_reply": "2023-05-10T14:06:40.330778Z",
          "shell.execute_reply.started": "2023-05-10T14:06:40.270904Z"
        },
        "id": "M1APZJfBAXxY"
      },
      "outputs": [],
      "source": [
        "labels = styles_df[\"subCategory\"][styles_df[\"subCategory\"].isin(labels_unique)]\n",
        "val, cnt = np.unique(labels, return_counts=True)\n",
        "for v, c in zip(val, cnt):\n",
        "    print(v, c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OdVcj2-AXxZ"
      },
      "source": [
        "Категория `Accessories` довольно общая, но при этом немногочисленная, ее можно исключить. То же касается категории `Free Gifts`. Категории `Flip Flops` и `Sandal` значительно пересекаются друг с другом, поэтому их лучше объединить."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-10T14:06:40.334365Z",
          "iopub.status.busy": "2023-05-10T14:06:40.333906Z",
          "iopub.status.idle": "2023-05-10T14:06:40.356802Z",
          "shell.execute_reply": "2023-05-10T14:06:40.355693Z",
          "shell.execute_reply.started": "2023-05-10T14:06:40.334305Z"
        },
        "id": "QL_Bu63KAXxZ"
      },
      "outputs": [],
      "source": [
        "labels_unique = labels_unique[~np.isin(labels_unique, [\"Accessories\",  \"Free Gifts\", \"Flip Flops\"])]\n",
        "styles_df[styles_df[\"subCategory\"] == \"Flip Flops\"] = \"Sandal\"\n",
        "styles_df = styles_df[styles_df[\"subCategory\"].isin(labels_unique)]\n",
        "num_classes, num_ids = len(labels_unique), len(styles_df.index)\n",
        "num_classes, num_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQpR59ocAXxZ"
      },
      "source": [
        "Составим карту отображения лейблов в классы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-10T14:06:40.358794Z",
          "iopub.status.busy": "2023-05-10T14:06:40.358326Z",
          "iopub.status.idle": "2023-05-10T14:06:40.369380Z",
          "shell.execute_reply": "2023-05-10T14:06:40.368120Z",
          "shell.execute_reply.started": "2023-05-10T14:06:40.358758Z"
        },
        "id": "mh7AM_s-AXxa"
      },
      "outputs": [],
      "source": [
        "label2class = {label: i for i, label in enumerate(labels_unique)}\n",
        "label2class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD4fNA7oAXxa"
      },
      "source": [
        "Проверим, для всех ли идентификаторов из таблицы стилей есть соответствующие изображения. Удалим идентификаторы, для которых изображения не нашлись."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-10T14:06:40.371062Z",
          "iopub.status.busy": "2023-05-10T14:06:40.370652Z",
          "iopub.status.idle": "2023-05-10T14:08:23.203294Z",
          "shell.execute_reply": "2023-05-10T14:08:23.202354Z",
          "shell.execute_reply.started": "2023-05-10T14:06:40.371029Z"
        },
        "id": "H4JbxtwlAXxa"
      },
      "outputs": [],
      "source": [
        "not_found_ids = []\n",
        "for id in tqdm(styles_df.index):\n",
        "    if not (images_root / f'{id}.jpg').exists():\n",
        "        not_found_ids.append(id)\n",
        "styles_df = styles_df[~styles_df.index.isin(not_found_ids)]\n",
        "\n",
        "# Проверим, что в таблице остались только уникальные идентификаторы.\n",
        "assert len(styles_df.index) == len(np.unique(styles_df.index))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceNTlzkJAXxb"
      },
      "source": [
        "Реализуем класс для работы с данными."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-10T14:08:23.226844Z",
          "iopub.status.busy": "2023-05-10T14:08:23.226481Z",
          "iopub.status.idle": "2023-05-10T14:08:23.235549Z",
          "shell.execute_reply": "2023-05-10T14:08:23.234685Z",
          "shell.execute_reply.started": "2023-05-10T14:08:23.226810Z"
        },
        "id": "BZynXnGlAXxb"
      },
      "outputs": [],
      "source": [
        "class StylesDataset(Dataset):\n",
        "    def __init__(self, images_root, styles_df, label2class, ids, transform):\n",
        "        self.images_root = images_root\n",
        "        self.styles_df = styles_df\n",
        "        self.label2class = label2class\n",
        "        self.ids = ids\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    @lru_cache(maxsize=400)\n",
        "    def __getitem__(self, i):\n",
        "        id = self.ids[i]\n",
        "        image = Image.open(self.images_root / f'{id}.jpg')\n",
        "        image = self.transform(image)\n",
        "        label = self.styles_df.loc[id, 'subCategory']\n",
        "        cls = self.label2class[label]\n",
        "        return image, cls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUqQGtFlqmaV"
      },
      "source": [
        "### 2. Обучение моделей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jgcuhkxhqhxd"
      },
      "source": [
        "Модели можно выбрать из [timm](https://github.com/huggingface/pytorch-image-models), [torchvision](https://pytorch.org/vision/stable/models.html) или [huggingface](https://huggingface.co/docs/transformers/index). В качестве сверточной модели можно использовать EfficientNet или более мощную модель. Более мощную модель будем определять по рейтингу top-1 моделей предобученных на ImageNet. Для сравнения моделей можно воспользоваться [рейтингом paperswithcode](https://paperswithcode.com/sota/image-classification-on-imagenet) или соотвествующими результатами в научных статьях, посвященным моделям для классификации изображений. В качестве трансформерной модели можно использовать ViT, DeiT, CeiT, VOLO, SWIN или более мощные модели. Для того, чтобы достигнуть хорошего качества, используйте уже предобученные модели.\n",
        "\n",
        "*Задача*  &mdash;  для разных обучающих наборов данных: 2000, 8000 снимков и всего набора данных (42749 снимков) посчитайте weighted accuracy (усредненную accuracy по всем классам) для сверточной и трансформерной моделей. На тест выделите 1000 снимков. На большом объеме данных трансформерная модель не должна быть сильно хуже сверточной. На всем датасете обе модели должны пробить порог weighted accuracy равный 0.8.\n",
        "\n",
        "Возможно, *для улучшения качества трансформера* вам могут помочь:\n",
        "- [пример](https://keras.io/examples/vision/vit_small_ds/) с построением трансформерной модели на keras, где описываются аугментации, shifted patches, local attention;\n",
        "- [статья](https://arxiv.org/pdf/2106.03746.pdf), где используют доп. лосс для обучения произвольной трансформерной модели на небольшом объеме данных.\n",
        "\n",
        "*Правила проведения экспериментов*.\n",
        "- Для всех экспериментов используйте одинаковый пайплайн семплирования данных &mdash; аугментации, размер батча, метод выбора данных для формирования батча.\n",
        "- Для экспериментов с одинаковым количеством обучающих данных используйте одинакове число эпох для обучения. \n",
        "- Для каждой модели (сверточной и трансформерной) зафиксируйте пайплайн обучения &mdash; саму модель, оптимизатор, learing rate scheduling, регуляризацию весов модели, лоссы.\n",
        "- Поясните выбор стратегии семплирования данных и пайпайна обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTyLthxiOziV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StINKUakr2xU"
      },
      "source": [
        "### 3. Анализ моделей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Оцените размеры моделей (MB). Сравните время вычислений (сек.) и затрачиваемую память (MB) на обучении и на инференсе для обеих моделей."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "2. Выберите лучшие сверточную и трансформерную модели и проведите анализ ошибок моделей. \n",
        "- Определите, в каких классах ошибались модели.\n",
        "- Визуализируйте примеры с правильными и неправильнымм предсказаниями для каждой модели.\n",
        "- Предположите, с чем связаны ошибки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSFtOLrvrFiB"
      },
      "source": [
        "3. Сделайте **выводы** по задаче."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHYHq-tMOdVi"
      },
      "source": [
        "## Задача 2 &mdash; Attention vs. Outlook attention\n",
        "\n",
        "Реализуйте классы 1 блока Attention и 1 блока Outlook attention.\n",
        "\n",
        "Примените написанные слои к случайному тензору или произвольной картинке. Сравните:\n",
        "* время вычислений (сек)\n",
        "* затрачиваемую память (MB)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elOmCi1_NvJH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JqMQVdLqB6H"
      },
      "source": [
        "Сделайте **выводы** по задаче."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}