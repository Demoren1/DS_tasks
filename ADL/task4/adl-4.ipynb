{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# DS-поток, весна 2025\n## Задание ADL.4\n### Подходы к оптимизации процесса обучения LLMs.\n\n**Правила:**\n\n* Дедлайны см. в боте. После дедлайна работы не принимаются кроме случаев наличия уважительной причины.\n* Выполненную работу нужно отправить телеграм-боту `@miptstats_ds24_bot`. Для начала работы с ботом каждый раз отправляйте `/start`. Дождитесь подтверждения от бота, что он принял файл. Если подтверждения нет, то что-то не так. **Работы, присланные иным способом, не принимаются.**\n* Дедлайны см. в боте. После дедлайна работы не принимаются кроме случаев наличия уважительной причины.\n* Прислать нужно **ноутбук в формате `ipynb`**.\n* Следите за размером файлов. **Бот не может принимать файлы весом более 20 Мб.** Если файл получается больше, заранее разделите его на несколько.\n* Выполнять задание необходимо полностью самостоятельно. **При обнаружении списывания все участники списывания получат штраф.**\n* Решения, размещенные на каких-либо интернет-ресурсах, не принимаются. Кроме того, публикация решения в открытом доступе может быть приравнена к предоставлении возможности списать.\n* Для выполнения задания используйте этот ноутбук в качестве основы, ничего не удаляя из него. Можно добавлять необходимое количество ячеек.\n* Комментарии к решению пишите в markdown-ячейках.\n* Выполнение задания (ход решения, выводы и пр.) должно быть осуществлено на русском языке.\n* Если код будет не понятен проверяющему, оценка может быть снижена.\n* Никакой код из данного задания при проверке запускаться не будет. *Если код студента не выполнен, недописан и т.д., то он не оценивается.*\n* В каждой задаче не забывайте делать **пояснения и выводы**.\n* **Код из рассказанных на занятиях ноутбуков** можно использовать без ограничений.\n\n**Баллы за задание:**\n\n* Реализация &mdash; 80 баллов;\n* Сравнение и анализ &mdash; 70 баллов.","metadata":{"id":"5qyq8YF-6S8s"}},{"cell_type":"code","source":"import time\n\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\n\nfrom collections import defaultdict\nimport itertools\nfrom tqdm.notebook import tqdm\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T15:53:19.144215Z","iopub.execute_input":"2025-04-25T15:53:19.144981Z","iopub.status.idle":"2025-04-25T15:53:23.584440Z","shell.execute_reply.started":"2025-04-25T15:53:19.144955Z","shell.execute_reply":"2025-04-25T15:53:23.583874Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Описание\n\nНа занятии мы познакомились с различными техниками, которые используются при обучении больших языковых моделей. В этом домашнем задании вам предстоит решить реальную практическую задачу, которая связана с оптимизацией некоторых слоев в трансформере.\n\nВспомним общую идею техники, которая называется Gradient Checkpointing. Идея заключается в том, чтобы на этапе forward'a не запоминать промежуточные активации, необходимые для backward'a, а вычислять их непосредственно на этапе backward'a. Почему это может быть важно? Оказывается, что активации MLP для больших моделей занимают очень много памяти. Сохранить для backward'а все активации, включая слои внимания, просто невозможно. Возникает вопрос: стоит ли сохранять промежуточные активации MLP или же отдать память под активации attention'a? На практике пересчет активаций для MLP оказывается гораздо быстрее, чем пересчет того же attention'a. В итоге мы можем не сохранять активации MLP, экономить достаточно много памяти, а часть освободившейся памяти отдать под активации attention'a и тем самым даже ускорить обучение!\n\n## Реализация\nСегодня мы не будем работать с полноценным трансформером, а сфокусируемся только на MLP-блоке. Вам предлагается написать модифицированный слой MLP таким образом, чтобы он поддерживал возможность либо сохранять промежуточные активации, либо пересчитывать их на этапе backward'a. Оформить код нужно будет в виде кастомной `torch.autograd.Function`. Хорошая практика заключается в том, чтобы ваш итоговый слой, который наследуется от `torch.nn.Module` просто вызывал функцию с нужными параметрами. Вам нужно **обязательно** ознакомиться с [постом](https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html), в котором вы узнаете, как правильно написать кастомную `torch.autograd.Function` функцию и что это вообще такое.\n\n\nВспомним с лекции, как выглядит модифицированный MLP для современных арихетктур.\n$$\n\\text{FFN}_{\\text{SwiGLU}}\\left(x, W, V, U\\right) = \\left(\\text{Swish}_1\\left(xW\\right)\\otimes xV\\right)U = \\left(\\text{SiLU}\\left(xW\\right)\\otimes xV\\right)U,\n$$\nгде\n$$\n\\text{Swish}_1\\left(x\\right)= \\text{SiLU}\\left(x\\right) = x\\sigma\\left(x\\right)\n$$\n\nТакой MLP-блок используется в [LLaMA](https://arxiv.org/abs/2307.09288)-подобных архитектурах. В этом задании будем использовать его. Посмотрим, как выглядит реализация в виде простого `torch.nn.Module`.","metadata":{"id":"aU9xjOMyYurQ"}},{"cell_type":"code","source":"class SwigluMLP(nn.Module):\n    def __init__(self, hidden_size, intermediate_size):\n        super().__init__()\n        self.W = nn.Linear(hidden_size, intermediate_size, bias=False)\n        self.V = nn.Linear(hidden_size, intermediate_size, bias=False)\n        self.U = nn.Linear(intermediate_size, hidden_size, bias=False)\n        self.act_fn = nn.SiLU()\n\n    def forward(self, x):\n        output = self.U(self.act_fn(self.W(x)) * self.V(x))\n        return output","metadata":{"id":"5fdC5ZZ4tIsg","trusted":true,"execution":{"iopub.status.busy":"2025-04-25T15:53:23.585529Z","iopub.execute_input":"2025-04-25T15:53:23.585928Z","iopub.status.idle":"2025-04-25T15:53:23.591315Z","shell.execute_reply.started":"2025-04-25T15:53:23.585906Z","shell.execute_reply":"2025-04-25T15:53:23.590513Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"Теперь перейдем к нашей реализации. Обратите внимание, что `MemoryOptimizedSwigluMLPFunction` принимает на вход `checkpoint_level`. Это переменная нужна для реализации следующей логики:\n* `checkpoint_level == 0` &mdash; никаких оптимизаций не проводится, промежуточные активации просто сохраняются для переиспользования на этапе backward'a через `ctx.save_for_backward(...)`;\n* `checkpoint_level == 1` &mdash; для backward'a сохраняются только вход `x` и матрицы `W, V, U`, а на этапе backward'a нужные активации просто снова пересчитываются.\n\nВам нужно реализовать методы `forward` и `backward`. Реализация второго потребует от вас посчитать некоторые промежуточные градиенты в матричном виде. Обязательно **выпишите и поясните** получающиеся формулы.","metadata":{"id":"VRH0ZKgcxizx"}},{"cell_type":"markdown","source":"Пусть l = $\\frac{\\partial L}{\\partial F}$\n\nz = $SiLu(xW) \\circ xV$\n\n$$\n\\frac{\\partial L}{\\partial z} = l \\cdot U_t\n$$\n\n$$\n\\frac{\\partial z}{\\partial xV} = SiLu(xW)\n$$\n\n\n$$\n\\frac{\\partial z}{\\partial SiLu(xW)} = xV\n$$\n\nМы помним, что $(x \\sigma(x))' = \\sigma(x) + x \\sigma(x) \\cdot(1 - \\sigma(x)) = \\sigma(x) (1 + x - \\sigma(x))$\n$$\n\\frac{\\partial SiLu(xW)}{\\partial xW} = \\sigma(xW) (xW + 1 - \\sigma(xW))\n$$\n\n$$\n\\frac{\\partial (xW)}{\\partial x} = W\n$$\n\n$$\n\\frac{\\partial (xV)}{\\partial x} = W\n$$","metadata":{}},{"cell_type":"markdown","source":"Выпишем наконец нужные нам градиенты:\n\n$$\n\\frac{\\partial (L)}{\\partial W} = \\frac{\\partial (L)}{\\partial z} \\frac{\\partial (z)}{\\partial SiLu(xW)}\\frac{\\partial SiLu(xW)}{\\partial xW} \\cdot x\n$$\n\n$$\n\\frac{\\partial (L)}{\\partial V} = \\frac{\\partial (L)}{\\partial z} \\frac{\\partial (z)}{\\partial xV} \\cdot x\n$$\n\n\n$$\n\\frac{\\partial (L)}{\\partial x} = \\frac{\\partial (L)}{\\partial z} \\left(\\frac{\\partial (z)}{\\partial SiLu(xW)}\\frac{\\partial SiLu(xW)}{\\partial xW} \\cdot W + \\frac{\\partial (z)}{\\partial xV} \\cdot V\\right)\n$$\n\n$$\n\\frac{\\partial (L)}{\\partial U} = z^T \\cdot l\n$$","metadata":{}},{"cell_type":"code","source":"class MemoryOptimizedSwigluMLPFunction(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x, W, V, U, checkpoint_level):\n        # x: (batch, seq_len, hidden_dim)\n        xW_raw   = torch.matmul(x, W)                   # (batch, seq_len, inter)\n        xW_silu  = torch.sigmoid(xW_raw) * xW_raw        # SiLU activation\n        xV       = torch.matmul(x, V)                   # (batch, seq_len, inter)\n        z        = xW_silu * xV                         # elementwise\n        output   = torch.matmul(z, U)                   # (batch, seq_len, out_dim)\n\n        ctx.checkpoint_level = checkpoint_level\n        if checkpoint_level == 0:\n            ctx.save_for_backward(x, W, V, U, xW_raw, xW_silu, xV)\n        else:\n            ctx.save_for_backward(x, W, V, U)\n        return output\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        checkpoint_level = ctx.checkpoint_level\n        saved = ctx.saved_tensors\n\n        if checkpoint_level == 0:\n            x, W, V, U, xW_raw, xW_silu, xV = saved\n        else:\n            x, W, V, U = saved\n            xW_raw   = torch.matmul(x, W)\n            xW_silu  = torch.sigmoid(xW_raw) * xW_raw\n            xV       = torch.matmul(x, V)\n\n        # 1) вычислим градиент z\n        grad_z = grad_output.matmul(U.t())\n\n        # 2) вычислим градиенты по silu(xW) и xV\n        grad_xW_silu = grad_z * xV\n        grad_xV      = grad_z * xW_silu\n\n        # 3) выпичислим производную silu(xW) по xW\n        sigma = torch.sigmoid(xW_raw)\n        d_silu = sigma * (1 + xW_raw * (1 - sigma))\n\n        # 4) вычислим  производную L по xW\n        grad_xW_raw = grad_xW_silu * d_silu\n\n        # 5) Наконец вычислим необходимые градиенты\n        # U: z^T @ grad_output\n        z_flat      = (xW_silu * xV).reshape(-1, xW_silu.size(-1))\n        go_flat     = grad_output.reshape(-1, grad_output.size(-1))\n        grad_U      = z_flat.t().matmul(go_flat)\n\n        # W: x^T @ grad_xW_raw\n        dxW_flat    = grad_xW_raw.reshape(-1, grad_xW_raw.size(-1))\n        x_flat      = x.reshape(-1, x.size(-1))\n        grad_W      = x_flat.t().matmul(dxW_flat)\n\n        # V: x^T @ grad_xV\n        dxV_flat    = grad_xV.reshape(-1, grad_xV.size(-1))\n        grad_V      = x_flat.t().matmul(dxV_flat)\n\n        # 6) Вычислим градиент по x\n        grad_x_from_W = grad_xW_raw.matmul(W.t())\n        grad_x_from_V = grad_xV.matmul(V.t())\n        grad_x        = grad_x_from_W + grad_x_from_V\n\n        return grad_x, grad_W, grad_V, grad_U, None\n        \n# Определим новый класс, реализующий оптимизированный MLP-слой\nclass MemoryOptimizedSwigluMLP(nn.Module):\n    def __init__(self, hidden_size, intermediate_size, checkpoint_level):\n        super(MemoryOptimizedSwigluMLP, self).__init__()\n        self.W = nn.Parameter(torch.empty(hidden_size, intermediate_size))\n        self.V = nn.Parameter(torch.empty(hidden_size, intermediate_size))\n        self.U = nn.Parameter(torch.empty(intermediate_size, hidden_size))\n        self.checkpoint_level = checkpoint_level\n\n    def forward(self, x):\n        return MemoryOptimizedSwigluMLPFunction.apply(\n            x,\n            self.W,\n            self.V,\n            self.U,\n            self.checkpoint_level\n        )","metadata":{"id":"rPK-tVC_xmgW","trusted":true,"execution":{"iopub.status.busy":"2025-04-25T15:53:23.592008Z","iopub.execute_input":"2025-04-25T15:53:23.592198Z","iopub.status.idle":"2025-04-25T15:53:23.610974Z","shell.execute_reply.started":"2025-04-25T15:53:23.592181Z","shell.execute_reply":"2025-04-25T15:53:23.610346Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"Теперь проверим, что реализованный MLP-слой считается верно.","metadata":{"id":"ZaKpdWgt0lqR"}},{"cell_type":"code","source":"# Зададим параметры\nbatch_size = 4\nseq_len = 256\nhidden_dim = 768\n\ndummy_input = torch.randn(batch_size, seq_len, hidden_dim)\n# Обратите внимание, что intermediate_size кратно больше hidden_dim\n# Это типичное \"расширение\", характерное для MLP (FFN) слоя в трансформере\nswiglu_mlp = SwigluMLP(hidden_dim, hidden_dim * 3)\noptimized_swiglu_mlp = MemoryOptimizedSwigluMLP(hidden_dim, hidden_dim * 3, checkpoint_level=1)\n\n# Скопируем параметры, чтобы они были одинаковые\nwith torch.no_grad():\n    optimized_swiglu_mlp.W.data = swiglu_mlp.W.weight.data.t()\n    optimized_swiglu_mlp.V.data = swiglu_mlp.V.weight.data.t()\n    optimized_swiglu_mlp.U.data = swiglu_mlp.U.weight.data.t()\n\n# Прогоним модель\nstandard_output = swiglu_mlp(dummy_input)\noptimized_output = optimized_swiglu_mlp(dummy_input)\n\n# Проверим выходы слоев на совпадение\nassert torch.allclose(standard_output, optimized_output, atol=1e-4)\n\nstandard_output.sum().backward()\noptimized_output.sum().backward()\n\n# Проверим на совпадение градиенты\nassert torch.allclose(swiglu_mlp.U.weight.grad, optimized_swiglu_mlp.U.grad.t(), atol=1e-4)\nassert torch.allclose(swiglu_mlp.V.weight.grad, optimized_swiglu_mlp.V.grad.t(), atol=1e-4)\nassert torch.allclose(swiglu_mlp.W.weight.grad, optimized_swiglu_mlp.W.grad.t(), atol=1e-4)\nprint(\"ALL ASSERTS PASSED\")","metadata":{"id":"-PaLwg0_0qlZ","trusted":true,"execution":{"iopub.status.busy":"2025-04-25T15:53:23.612294Z","iopub.execute_input":"2025-04-25T15:53:23.612486Z","iopub.status.idle":"2025-04-25T15:53:24.207508Z","shell.execute_reply.started":"2025-04-25T15:53:23.612471Z","shell.execute_reply":"2025-04-25T15:53:24.206648Z"}},"outputs":[{"name":"stdout","text":"ALL ASSERTS PASSED\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Сравнение и анализ\n\nСравните время исполнение forward/backward и объем потребляемой памяти в зависимости от значения `checkpoint_level`. Проведите эксперименты для разных значений `batch_size`, `seq_len`, `hidden_dim`. Сделайте запуски в нескольких сетапах. Попробуйте достаточно большие `seq_len=1024` и `hidden_dim=4096`, а также `num_layers=5`. Сделайте выводы.\n\nНекоторые советы:\n* Для отслеживания потребляемой памяти можете воспользоваться `torch.cuda.max_memory_allocated()`. Желательно после каждого шага очищать статистику, используя `torch.cuda.reset_peak_memory_stats()`. Более подробно рекомендуется почитать документацию по [ссылке](https://pytorch.org/docs/stable/notes/cuda.html#cuda-memory-management).\n* Для подсчета времени можно воспользоваться простым ` time.perf_counter()` или же `time.time()`. Однако с подсчетом времени для GPU-операций все немного хитрее. В PyTorch и других библиотеках, работающих с GPU, операции выполняются асинхронно по отношению к коду, исполняемому на CPU. Такой подход позволяет CPU продолжать работу, не ожидая окончания каждой операции на GPU, что способствует повышению общей производительности за счёт параллельной работы CPU и GPU. Что это значит на практике? Вы можете получить завышенные результаты своих измерений, так как замер времени может завершиться до того, как GPU в действительности закончит выполнение операций.\nРассмотрим пример кода:\n```\na = torch.rand(10000, 10000, device=\"cuda\")\nstart_time = time.time()\nb = a @ a\nelapsed_time = time.time() - start_time\n```\nВ этом примере, после запуска операции умножения матриц `a @ a`, мы немедленно измеряем время выполнения функции, не дожидаясь её фактического завершения на GPU.\nДля получения точных измерений времени выполнения операций на GPU необходимо использовать синхронизацию. В PyTorch это можно сделать с помощью функции `torch.cuda.synchronize()`, которая блокирует выполнение кода на CPU до тех пор, пока все запланированные задачи на соответствующем GPU не будут завершены. \\\nПример более грамотного кода:\n```\na = torch.rand(10000, 10000, device='cuda')\ntorch.cuda.synchronize() # ждем завершения всех предыдущих операций на GPU\nstart_time = time.time()\nb = a @ a\ntorch.cuda.synchronize() # cнова синхронизируемся, чтобы убедиться, что операция завершена\nelapsed_time = time.time() - start_time\n```\n* Для подсчета статистики следует сделать несколько проходов forward/backward для одной модели, а полученные результаты просто усреднить. Для более стабильных результатов выполните также разогрев, то есть некоторое количество прогонов модели перед основным измерением. Это важно, т.к. на результаты измерений могут повлиять дополнительные задержки, связанные с инициализацией и загрузкой ресурсов, температурой GPU, а также различные кэши.\n* Представьте результаты и выводы в информативном виде, хорошо подойдет какая-нибудь табличка. Затраты по памяти лучше всего указать в Гб, а время исполнения в секундах.","metadata":{"id":"Ytfh5Nzk4F7p"}},{"cell_type":"code","source":"# используем несколько слоев, чтобы увидеть выигрыш по памяти\n# в случае chechkpoint_level == 0 для вычислений очередного слоя будет использована та память, \n# что осталась для предыдущего\n# если же checkpoint_level == 1, то придется хранить активации для всех слоев\n\nclass TestTransformer(nn.Module):\n    def __init__(self, num_layers, hidden_size, intermediate_size, checkpoint_level):\n        super(TestTransformer, self).__init__()\n        self.layers = nn.ModuleList([\n            MemoryOptimizedSwigluMLP(hidden_size, intermediate_size, checkpoint_level)\n            for _ in range(num_layers)\n        ])\n\n    def forward(self, x):\n        for layer in self.layers:\n            x = layer(x)\n        return x","metadata":{"id":"nreczZ67-cKo","trusted":true,"execution":{"iopub.status.busy":"2025-04-25T15:53:24.208313Z","iopub.execute_input":"2025-04-25T15:53:24.208527Z","iopub.status.idle":"2025-04-25T15:53:24.213331Z","shell.execute_reply.started":"2025-04-25T15:53:24.208511Z","shell.execute_reply":"2025-04-25T15:53:24.212765Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"Реализация функции для бенчмарка.","metadata":{}},{"cell_type":"code","source":"def benchmark_transformer(model, batch_size, seq_len, hidden_dim, num_warmup_steps, num_steps):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    statistics = defaultdict(list)\n    \n    # Генерация входных данных\n    input_tensor = torch.randn(batch_size, seq_len, hidden_dim, device=device, requires_grad=True)\n    model.to(device)\n\n    # Warmup GPU чтобы избежать заниженного перфоманса\n    for _ in range(num_warmup_steps):\n        output = model(input_tensor)\n        output.sum().backward()\n        torch.cuda.synchronize()\n\n    # Основное измерение\n    for _ in range(num_steps):\n        torch.cuda.reset_peak_memory_stats()\n        \n        torch.cuda.synchronize()\n        start_time_forward = time.time()\n        \n        output = model(input_tensor)\n        \n        torch.cuda.synchronize()\n        end_time_forward = time.time()\n\n        torch.cuda.synchronize()\n        start_time_backward = time.time()\n        \n        output.sum().backward()\n\n        torch.cuda.synchronize()\n        end_time_backward = time.time()\n\n        allocated_memory = torch.cuda.max_memory_allocated() / (1024 ** 3)\n        time_consumed_forward = end_time_forward - start_time_forward\n        time_consumed_backward = end_time_backward - start_time_backward\n\n        statistics[\"forward_time, s\"].append(round(time_consumed_forward, 3))\n        statistics[\"backward_time, s\"].append(round(time_consumed_backward, 3))\n        statistics[\"peak_memory, Gb\"].append(round(allocated_memory, 3))\n    \n    statistics_df = pd.DataFrame(statistics).mean(axis=0)\n    return statistics_df","metadata":{"id":"m3qiIeNw-4xE","trusted":true,"execution":{"iopub.status.busy":"2025-04-25T15:53:24.213995Z","iopub.execute_input":"2025-04-25T15:53:24.214256Z","iopub.status.idle":"2025-04-25T15:53:24.235457Z","shell.execute_reply.started":"2025-04-25T15:53:24.214238Z","shell.execute_reply":"2025-04-25T15:53:24.234705Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def run_experiments():\n    experiment_configs = [\n    # seq_len = 128, hidden_dim = 512, num_layers = 2\n    {\"batch_size\": 16,  \"seq_len\": 128,  \"hidden_dim\": 512,  \"intermediate_size\": 2048,  \"num_layers\": 2, \"checkpoint_level\": 0},\n    {\"batch_size\": 16,  \"seq_len\": 128,  \"hidden_dim\": 512,  \"intermediate_size\": 2048,  \"num_layers\": 2, \"checkpoint_level\": 1},\n    {\"batch_size\": 32,  \"seq_len\": 128,  \"hidden_dim\": 512,  \"intermediate_size\": 2048,  \"num_layers\": 2, \"checkpoint_level\": 0},\n    {\"batch_size\": 32,  \"seq_len\": 128,  \"hidden_dim\": 512,  \"intermediate_size\": 2048,  \"num_layers\": 2, \"checkpoint_level\": 1},\n\n    # seq_len = 512, hidden_dim = 1024, num_layers = 3\n    {\"batch_size\": 8,  \"seq_len\": 512,  \"hidden_dim\": 1024, \"intermediate_size\": 4096,  \"num_layers\": 3, \"checkpoint_level\": 0},\n    {\"batch_size\": 8,  \"seq_len\": 512,  \"hidden_dim\": 1024, \"intermediate_size\": 4096,  \"num_layers\": 3, \"checkpoint_level\": 1},\n    {\"batch_size\": 16,  \"seq_len\": 512,  \"hidden_dim\": 1024, \"intermediate_size\": 4096,  \"num_layers\": 3, \"checkpoint_level\": 0},\n    {\"batch_size\": 16,  \"seq_len\": 512,  \"hidden_dim\": 1024, \"intermediate_size\": 4096,  \"num_layers\": 3, \"checkpoint_level\": 1},\n\n    # seq_len = 1024, hidden_dim = 4096, num_layers = 5\n    {\"batch_size\": 4,  \"seq_len\": 1024, \"hidden_dim\": 4096, \"intermediate_size\": 16384, \"num_layers\": 5, \"checkpoint_level\": 0},\n    {\"batch_size\": 4,  \"seq_len\": 1024, \"hidden_dim\": 4096, \"intermediate_size\": 16384, \"num_layers\": 5, \"checkpoint_level\": 1},\n    ]\n    \n    all_results = []\n\n    for config in tqdm(experiment_configs):\n        print(f\"Running: {config}\")\n        model = TestTransformer(\n            num_layers=config[\"num_layers\"],\n            hidden_size=config[\"hidden_dim\"],\n            intermediate_size=config[\"intermediate_size\"],\n            checkpoint_level=config[\"checkpoint_level\"]\n        )\n        stats = benchmark_transformer(\n            model=model,\n            batch_size=config[\"batch_size\"],\n            seq_len=config[\"seq_len\"],\n            hidden_dim=config[\"hidden_dim\"],\n            num_warmup_steps=2,\n            num_steps=15,\n        )\n\n        stats = stats.to_dict()\n        stats.update(config)\n        all_results.append(stats)\n\n    return pd.DataFrame(all_results)","metadata":{"id":"1uZmZUcCwt8j","trusted":true,"execution":{"iopub.status.busy":"2025-04-25T15:53:24.236371Z","iopub.execute_input":"2025-04-25T15:53:24.236546Z","iopub.status.idle":"2025-04-25T15:53:24.256627Z","shell.execute_reply.started":"2025-04-25T15:53:24.236524Z","shell.execute_reply":"2025-04-25T15:53:24.255980Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"run_experiments()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T15:53:24.257455Z","iopub.execute_input":"2025-04-25T15:53:24.257735Z","iopub.status.idle":"2025-04-25T15:55:38.830316Z","shell.execute_reply.started":"2025-04-25T15:53:24.257718Z","shell.execute_reply":"2025-04-25T15:55:38.829740Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"033e440521c743bd982679dc2762e9fb"}},"metadata":{}},{"name":"stdout","text":"Running: {'batch_size': 16, 'seq_len': 128, 'hidden_dim': 512, 'intermediate_size': 2048, 'num_layers': 2, 'checkpoint_level': 0}\nRunning: {'batch_size': 16, 'seq_len': 128, 'hidden_dim': 512, 'intermediate_size': 2048, 'num_layers': 2, 'checkpoint_level': 1}\nRunning: {'batch_size': 32, 'seq_len': 128, 'hidden_dim': 512, 'intermediate_size': 2048, 'num_layers': 2, 'checkpoint_level': 0}\nRunning: {'batch_size': 32, 'seq_len': 128, 'hidden_dim': 512, 'intermediate_size': 2048, 'num_layers': 2, 'checkpoint_level': 1}\nRunning: {'batch_size': 8, 'seq_len': 512, 'hidden_dim': 1024, 'intermediate_size': 4096, 'num_layers': 3, 'checkpoint_level': 0}\nRunning: {'batch_size': 8, 'seq_len': 512, 'hidden_dim': 1024, 'intermediate_size': 4096, 'num_layers': 3, 'checkpoint_level': 1}\nRunning: {'batch_size': 16, 'seq_len': 512, 'hidden_dim': 1024, 'intermediate_size': 4096, 'num_layers': 3, 'checkpoint_level': 0}\nRunning: {'batch_size': 16, 'seq_len': 512, 'hidden_dim': 1024, 'intermediate_size': 4096, 'num_layers': 3, 'checkpoint_level': 1}\nRunning: {'batch_size': 4, 'seq_len': 1024, 'hidden_dim': 4096, 'intermediate_size': 16384, 'num_layers': 5, 'checkpoint_level': 0}\nRunning: {'batch_size': 4, 'seq_len': 1024, 'hidden_dim': 4096, 'intermediate_size': 16384, 'num_layers': 5, 'checkpoint_level': 1}\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   forward_time, s  backward_time, s  peak_memory, Gb  batch_size  seq_len  \\\n0         0.004267          0.009267            0.305          16      128   \n1         0.004000          0.012000            0.258          16      128   \n2         0.008000          0.018000            0.535          32      128   \n3         0.008000          0.023000            0.442          32      128   \n4         0.042133          0.092400            1.469           8      512   \n5         0.042200          0.118533            1.094           8      512   \n6         0.080267          0.180000            2.594          16      512   \n7         0.080267          0.232867            1.844          16      512   \n8         0.993467          2.016467           14.391           4     1024   \n9         0.993933          2.667533           11.391           4     1024   \n\n   hidden_dim  intermediate_size  num_layers  checkpoint_level  \n0         512               2048           2                 0  \n1         512               2048           2                 1  \n2         512               2048           2                 0  \n3         512               2048           2                 1  \n4        1024               4096           3                 0  \n5        1024               4096           3                 1  \n6        1024               4096           3                 0  \n7        1024               4096           3                 1  \n8        4096              16384           5                 0  \n9        4096              16384           5                 1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>forward_time, s</th>\n      <th>backward_time, s</th>\n      <th>peak_memory, Gb</th>\n      <th>batch_size</th>\n      <th>seq_len</th>\n      <th>hidden_dim</th>\n      <th>intermediate_size</th>\n      <th>num_layers</th>\n      <th>checkpoint_level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.004267</td>\n      <td>0.009267</td>\n      <td>0.305</td>\n      <td>16</td>\n      <td>128</td>\n      <td>512</td>\n      <td>2048</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.004000</td>\n      <td>0.012000</td>\n      <td>0.258</td>\n      <td>16</td>\n      <td>128</td>\n      <td>512</td>\n      <td>2048</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.008000</td>\n      <td>0.018000</td>\n      <td>0.535</td>\n      <td>32</td>\n      <td>128</td>\n      <td>512</td>\n      <td>2048</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.008000</td>\n      <td>0.023000</td>\n      <td>0.442</td>\n      <td>32</td>\n      <td>128</td>\n      <td>512</td>\n      <td>2048</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.042133</td>\n      <td>0.092400</td>\n      <td>1.469</td>\n      <td>8</td>\n      <td>512</td>\n      <td>1024</td>\n      <td>4096</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.042200</td>\n      <td>0.118533</td>\n      <td>1.094</td>\n      <td>8</td>\n      <td>512</td>\n      <td>1024</td>\n      <td>4096</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.080267</td>\n      <td>0.180000</td>\n      <td>2.594</td>\n      <td>16</td>\n      <td>512</td>\n      <td>1024</td>\n      <td>4096</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.080267</td>\n      <td>0.232867</td>\n      <td>1.844</td>\n      <td>16</td>\n      <td>512</td>\n      <td>1024</td>\n      <td>4096</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.993467</td>\n      <td>2.016467</td>\n      <td>14.391</td>\n      <td>4</td>\n      <td>1024</td>\n      <td>4096</td>\n      <td>16384</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.993933</td>\n      <td>2.667533</td>\n      <td>11.391</td>\n      <td>4</td>\n      <td>1024</td>\n      <td>4096</td>\n      <td>16384</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"**Вывод:**","metadata":{}},{"cell_type":"markdown","source":"Мы видим, что честный обсчет активаций увеличивает премя работы backward pass примерно на 20%, но при этом экономится порядка 15-30% процентов от затраченной видеопамяти. Причем экономия спадает с увеличением значений парметров.\n\nТаким образом, мы действительно наблюдаем выигрыш в видеопамяти, но нужно учитывать, что он обходится нам увеличением времени обучения.","metadata":{}}]}